{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "756ebd84",
   "metadata": {},
   "source": [
    "111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca6e786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    user_id             song_id  plays\n",
      "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995      1\n",
      "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9      1\n",
      "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B      2\n",
      "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22      1\n",
      "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# åŠ è½½æ’­æ”¾è®°å½•ï¼ˆç”¨æˆ·-æ­Œæ›²-æ’­æ”¾æ¬¡æ•°ï¼‰\n",
    "triplets = pd.read_csv('train_triplets.txt', sep='\\t', header=None, names=['user_id', 'song_id', 'plays'])\n",
    "print(triplets.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d847ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ‡é¢˜ç¼ºå¤±æ¯”ä¾‹: 0.0\n",
      "ç¤ºä¾‹æ•°æ®:\n",
      "                                    user_id             song_id  plays  \\\n",
      "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995      1   \n",
      "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9      1   \n",
      "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B      2   \n",
      "3  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFNSP12AF72A0E22      1   \n",
      "4  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBFOVM12A58A7D494      1   \n",
      "\n",
      "                             title  \n",
      "0                         The Cove  \n",
      "1             Nothing from Nothing  \n",
      "2                  Entre Dos Aguas  \n",
      "3            Under Cold Blue Stars  \n",
      "4  Riot Radio (Soundtrack Version)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "def load_metadata(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        songs_dataset = f['metadata']['songs']\n",
    "        \n",
    "        # æå–åŸå§‹å­—èŠ‚æ•°æ®\n",
    "        song_ids_bytes = songs_dataset['song_id'][()]  # å­—èŠ‚æ•°ç»„\n",
    "        titles_bytes = songs_dataset['title'][()]      # å­—èŠ‚æ•°ç»„\n",
    "        \n",
    "        # å®‰å…¨è§£ç ä¸º UTF-8ï¼ˆå¤„ç†éæ³•å­—ç¬¦ï¼‰\n",
    "        song_ids = [s.decode('utf-8', errors='ignore').strip() for s in song_ids_bytes]\n",
    "        titles = [t.decode('utf-8', errors='ignore').strip() for t in titles_bytes]\n",
    "        \n",
    "        # æ„å»º DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'song_id': song_ids,\n",
    "            'title': titles\n",
    "        })\n",
    "        \n",
    "        # ç§»é™¤ç©º song_id\n",
    "        df = df[df['song_id'].str.len() > 0]\n",
    "    return df\n",
    "\n",
    "metadata = load_metadata('msd_summary_file.h5')\n",
    "\n",
    "# åˆå¹¶æ•°æ®\n",
    "merged_data = pd.merge(\n",
    "    triplets,\n",
    "    metadata,\n",
    "    on='song_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# éªŒè¯ç»“æœ\n",
    "print(\"æ ‡é¢˜ç¼ºå¤±æ¯”ä¾‹:\", merged_data['title'].isnull().mean())\n",
    "print(\"ç¤ºä¾‹æ•°æ®:\")\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5370d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ æ£€æµ‹åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŠ è½½ä¸­...\n",
      "âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
      "ğŸ”„ å·²è°ƒæ•´å­¦ä¹ ç‡è‡³ 0.0001\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_input (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_embed (Embedding)          (None, 1, 16)        16309088    user_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "item_embed (Embedding)          (None, 1, 16)        6152736     item_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 16)           0           user_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 16)           0           item_embed[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dot_2 (Dot)                     (None, 1)            0           reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,461,824\n",
      "Trainable params: 22,461,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "2426/2426 [==============================] - 98s 40ms/step - loss: 8.4407e-07 - mae: 4.7321e-04 - val_loss: 1.3057e-06 - val_mae: 5.4719e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00000, saving model to best_model.keras\n",
      "Epoch 2/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 8.4063e-07 - mae: 4.7189e-04 - val_loss: 1.3023e-06 - val_mae: 5.4594e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 3/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 8.3650e-07 - mae: 4.7056e-04 - val_loss: 1.2992e-06 - val_mae: 5.4477e-04\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 4/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 8.3264e-07 - mae: 4.6927e-04 - val_loss: 1.2953e-06 - val_mae: 5.4363e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 5/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 8.2888e-07 - mae: 4.6801e-04 - val_loss: 1.2908e-06 - val_mae: 5.4252e-04\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 6/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 8.2524e-07 - mae: 4.6678e-04 - val_loss: 1.2872e-06 - val_mae: 5.4143e-04\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 7/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 8.2163e-07 - mae: 4.6557e-04 - val_loss: 1.2845e-06 - val_mae: 5.4037e-04\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 8/100\n",
      "2426/2426 [==============================] - 20s 8ms/step - loss: 8.1797e-07 - mae: 4.6437e-04 - val_loss: 1.2816e-06 - val_mae: 5.3931e-04\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 9/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 8.1504e-07 - mae: 4.6320e-04 - val_loss: 1.2790e-06 - val_mae: 5.3828e-04\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 10/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 8.1182e-07 - mae: 4.6204e-04 - val_loss: 1.2762e-06 - val_mae: 5.3726e-04\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 11/100\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 8.0850e-07 - mae: 4.6090e-04 - val_loss: 1.2721e-06 - val_mae: 5.3626e-04\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 12/100\n",
      "2426/2426 [==============================] - 20s 8ms/step - loss: 8.0558e-07 - mae: 4.5977e-04 - val_loss: 1.2690e-06 - val_mae: 5.3526e-04\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 13/100\n",
      "2426/2426 [==============================] - 27s 11ms/step - loss: 8.0224e-07 - mae: 4.5866e-04 - val_loss: 1.2658e-06 - val_mae: 5.3429e-04\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 14/100\n",
      "2426/2426 [==============================] - 27s 11ms/step - loss: 7.9862e-07 - mae: 4.5756e-04 - val_loss: 1.2629e-06 - val_mae: 5.3333e-04\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 15/100\n",
      "2426/2426 [==============================] - 20s 8ms/step - loss: 7.9511e-07 - mae: 4.5648e-04 - val_loss: 1.2603e-06 - val_mae: 5.3238e-04\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 16/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.9238e-07 - mae: 4.5541e-04 - val_loss: 1.2576e-06 - val_mae: 5.3144e-04\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 17/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.8945e-07 - mae: 4.5435e-04 - val_loss: 1.2544e-06 - val_mae: 5.3051e-04\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 18/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.8618e-07 - mae: 4.5331e-04 - val_loss: 1.2527e-06 - val_mae: 5.2960e-04\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 19/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.8287e-07 - mae: 4.5228e-04 - val_loss: 1.2498e-06 - val_mae: 5.2870e-04\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 20/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.7950e-07 - mae: 4.5126e-04 - val_loss: 1.2473e-06 - val_mae: 5.2781e-04\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 21/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.7684e-07 - mae: 4.5026e-04 - val_loss: 1.2445e-06 - val_mae: 5.2693e-04\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 22/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.7343e-07 - mae: 4.4926e-04 - val_loss: 1.2419e-06 - val_mae: 5.2606e-04\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 23/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.7040e-07 - mae: 4.4828e-04 - val_loss: 1.2400e-06 - val_mae: 5.2520e-04\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 24/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.6792e-07 - mae: 4.4731e-04 - val_loss: 1.2375e-06 - val_mae: 5.2436e-04\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 25/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.6487e-07 - mae: 4.4635e-04 - val_loss: 1.2343e-06 - val_mae: 5.2352e-04\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 26/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.6256e-07 - mae: 4.4541e-04 - val_loss: 1.2310e-06 - val_mae: 5.2270e-04\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 27/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.5947e-07 - mae: 4.4447e-04 - val_loss: 1.2279e-06 - val_mae: 5.2188e-04\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 28/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.5681e-07 - mae: 4.4355e-04 - val_loss: 1.2260e-06 - val_mae: 5.2108e-04\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 29/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.5458e-07 - mae: 4.4264e-04 - val_loss: 1.2238e-06 - val_mae: 5.2028e-04\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 30/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.5199e-07 - mae: 4.4173e-04 - val_loss: 1.2218e-06 - val_mae: 5.1949e-04\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 31/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.4988e-07 - mae: 4.4084e-04 - val_loss: 1.2197e-06 - val_mae: 5.1872e-04\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 32/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.4725e-07 - mae: 4.3996e-04 - val_loss: 1.2180e-06 - val_mae: 5.1795e-04\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 33/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.4492e-07 - mae: 4.3908e-04 - val_loss: 1.2157e-06 - val_mae: 5.1719e-04\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 34/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.4246e-07 - mae: 4.3822e-04 - val_loss: 1.2133e-06 - val_mae: 5.1644e-04\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 35/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.3993e-07 - mae: 4.3737e-04 - val_loss: 1.2103e-06 - val_mae: 5.1570e-04\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 36/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.3732e-07 - mae: 4.3652e-04 - val_loss: 1.2075e-06 - val_mae: 5.1497e-04\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 37/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.3496e-07 - mae: 4.3569e-04 - val_loss: 1.2054e-06 - val_mae: 5.1425e-04\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 38/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.3243e-07 - mae: 4.3486e-04 - val_loss: 1.2033e-06 - val_mae: 5.1353e-04\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 39/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.3041e-07 - mae: 4.3404e-04 - val_loss: 1.2017e-06 - val_mae: 5.1282e-04\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 40/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.2788e-07 - mae: 4.3324e-04 - val_loss: 1.1998e-06 - val_mae: 5.1212e-04\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 41/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.2574e-07 - mae: 4.3244e-04 - val_loss: 1.1976e-06 - val_mae: 5.1143e-04\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 42/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.2321e-07 - mae: 4.3164e-04 - val_loss: 1.1955e-06 - val_mae: 5.1075e-04\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 43/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.2090e-07 - mae: 4.3086e-04 - val_loss: 1.1937e-06 - val_mae: 5.1007e-04\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 44/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.1854e-07 - mae: 4.3009e-04 - val_loss: 1.1915e-06 - val_mae: 5.0940e-04\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 45/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.1631e-07 - mae: 4.2932e-04 - val_loss: 1.1896e-06 - val_mae: 5.0874e-04\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 46/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 7.1397e-07 - mae: 4.2856e-04 - val_loss: 1.1877e-06 - val_mae: 5.0808e-04\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 47/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.1132e-07 - mae: 4.2781e-04 - val_loss: 1.1860e-06 - val_mae: 5.0744e-04\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 48/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.0918e-07 - mae: 4.2707e-04 - val_loss: 1.1842e-06 - val_mae: 5.0680e-04\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 49/100\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 7.0702e-07 - mae: 4.2633e-04 - val_loss: 1.1827e-06 - val_mae: 5.0616e-04\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 50/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.0502e-07 - mae: 4.2561e-04 - val_loss: 1.1812e-06 - val_mae: 5.0553e-04\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 51/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.0328e-07 - mae: 4.2488e-04 - val_loss: 1.1790e-06 - val_mae: 5.0491e-04\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 52/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 7.0112e-07 - mae: 4.2417e-04 - val_loss: 1.1772e-06 - val_mae: 5.0430e-04\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 53/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.9910e-07 - mae: 4.2347e-04 - val_loss: 1.1751e-06 - val_mae: 5.0369e-04\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 54/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.9741e-07 - mae: 4.2277e-04 - val_loss: 1.1734e-06 - val_mae: 5.0309e-04\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 55/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.9559e-07 - mae: 4.2207e-04 - val_loss: 1.1709e-06 - val_mae: 5.0250e-04\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 56/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.9374e-07 - mae: 4.2139e-04 - val_loss: 1.1689e-06 - val_mae: 5.0191e-04\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 57/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.9212e-07 - mae: 4.2071e-04 - val_loss: 1.1681e-06 - val_mae: 5.0133e-04\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 58/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.9015e-07 - mae: 4.2004e-04 - val_loss: 1.1656e-06 - val_mae: 5.0075e-04\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 59/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.8824e-07 - mae: 4.1937e-04 - val_loss: 1.1641e-06 - val_mae: 5.0018e-04\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 60/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.8666e-07 - mae: 4.1871e-04 - val_loss: 1.1629e-06 - val_mae: 4.9961e-04\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 61/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.8519e-07 - mae: 4.1806e-04 - val_loss: 1.1611e-06 - val_mae: 4.9905e-04\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 62/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.8367e-07 - mae: 4.1741e-04 - val_loss: 1.1595e-06 - val_mae: 4.9850e-04\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 63/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.8160e-07 - mae: 4.1677e-04 - val_loss: 1.1581e-06 - val_mae: 4.9795e-04\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 64/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.7993e-07 - mae: 4.1614e-04 - val_loss: 1.1571e-06 - val_mae: 4.9741e-04\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 65/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.7782e-07 - mae: 4.1551e-04 - val_loss: 1.1560e-06 - val_mae: 4.9687e-04\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 66/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.7614e-07 - mae: 4.1489e-04 - val_loss: 1.1535e-06 - val_mae: 4.9634e-04\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 67/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.7420e-07 - mae: 4.1427e-04 - val_loss: 1.1521e-06 - val_mae: 4.9581e-04\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 68/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.7236e-07 - mae: 4.1366e-04 - val_loss: 1.1498e-06 - val_mae: 4.9529e-04\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 69/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.7101e-07 - mae: 4.1306e-04 - val_loss: 1.1479e-06 - val_mae: 4.9478e-04\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 70/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.6958e-07 - mae: 4.1246e-04 - val_loss: 1.1467e-06 - val_mae: 4.9426e-04\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 71/100\n",
      "2426/2426 [==============================] - 19s 8ms/step - loss: 6.6791e-07 - mae: 4.1186e-04 - val_loss: 1.1448e-06 - val_mae: 4.9376e-04\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 72/100\n",
      "2426/2426 [==============================] - 18s 8ms/step - loss: 6.6607e-07 - mae: 4.1127e-04 - val_loss: 1.1432e-06 - val_mae: 4.9326e-04\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 73/100\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 6.6432e-07 - mae: 4.1069e-04 - val_loss: 1.1426e-06 - val_mae: 4.9276e-04\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 74/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.6258e-07 - mae: 4.1011e-04 - val_loss: 1.1415e-06 - val_mae: 4.9227e-04\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 75/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.6063e-07 - mae: 4.0954e-04 - val_loss: 1.1401e-06 - val_mae: 4.9178e-04\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 76/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5909e-07 - mae: 4.0897e-04 - val_loss: 1.1391e-06 - val_mae: 4.9130e-04\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 77/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5771e-07 - mae: 4.0840e-04 - val_loss: 1.1373e-06 - val_mae: 4.9082e-04\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 78/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5619e-07 - mae: 4.0785e-04 - val_loss: 1.1359e-06 - val_mae: 4.9035e-04\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 79/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5471e-07 - mae: 4.0729e-04 - val_loss: 1.1343e-06 - val_mae: 4.8988e-04\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 80/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5306e-07 - mae: 4.0674e-04 - val_loss: 1.1329e-06 - val_mae: 4.8941e-04\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 81/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.5122e-07 - mae: 4.0620e-04 - val_loss: 1.1317e-06 - val_mae: 4.8895e-04\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 82/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4950e-07 - mae: 4.0566e-04 - val_loss: 1.1306e-06 - val_mae: 4.8849e-04\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 83/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4803e-07 - mae: 4.0513e-04 - val_loss: 1.1290e-06 - val_mae: 4.8804e-04\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 84/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4667e-07 - mae: 4.0460e-04 - val_loss: 1.1277e-06 - val_mae: 4.8759e-04\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 85/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4527e-07 - mae: 4.0407e-04 - val_loss: 1.1267e-06 - val_mae: 4.8715e-04\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 86/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4368e-07 - mae: 4.0355e-04 - val_loss: 1.1257e-06 - val_mae: 4.8671e-04\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 87/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4237e-07 - mae: 4.0303e-04 - val_loss: 1.1245e-06 - val_mae: 4.8627e-04\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 88/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.4095e-07 - mae: 4.0252e-04 - val_loss: 1.1239e-06 - val_mae: 4.8584e-04\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 89/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3955e-07 - mae: 4.0202e-04 - val_loss: 1.1225e-06 - val_mae: 4.8541e-04\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 90/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3842e-07 - mae: 4.0151e-04 - val_loss: 1.1217e-06 - val_mae: 4.8498e-04\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 91/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3701e-07 - mae: 4.0101e-04 - val_loss: 1.1202e-06 - val_mae: 4.8456e-04\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 92/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3574e-07 - mae: 4.0052e-04 - val_loss: 1.1185e-06 - val_mae: 4.8414e-04\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 93/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3461e-07 - mae: 4.0002e-04 - val_loss: 1.1177e-06 - val_mae: 4.8373e-04\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 94/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3362e-07 - mae: 3.9954e-04 - val_loss: 1.1163e-06 - val_mae: 4.8332e-04\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 95/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3227e-07 - mae: 3.9906e-04 - val_loss: 1.1149e-06 - val_mae: 4.8291e-04\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 96/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3116e-07 - mae: 3.9858e-04 - val_loss: 1.1140e-06 - val_mae: 4.8251e-04\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 97/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.3001e-07 - mae: 3.9810e-04 - val_loss: 1.1129e-06 - val_mae: 4.8211e-04\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 98/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.2863e-07 - mae: 3.9763e-04 - val_loss: 1.1118e-06 - val_mae: 4.8171e-04\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 99/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.2726e-07 - mae: 3.9716e-04 - val_loss: 1.1102e-06 - val_mae: 4.8132e-04\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "Epoch 100/100\n",
      "2426/2426 [==============================] - 17s 7ms/step - loss: 6.2598e-07 - mae: 3.9670e-04 - val_loss: 1.1086e-06 - val_mae: 4.8093e-04\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00000 to 0.00000, saving model to best_model.keras\n",
      "ğŸ’¾ å·²ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€è‡³ optimizer_state.pkl\n",
      "607/607 [==============================] - 1s 1ms/step - loss: 1.1086e-06 - mae: 4.8093e-04\n",
      "testsets MSE: 0.0000, MAE: 0.0005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['song_encoder.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Multiply, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------\n",
    "# æ•°æ®é¢„å¤„ç†\n",
    "# ----------------------\n",
    "\n",
    "# 1. ç”¨æˆ·å’Œæ­Œæ›²IDç¼–ç ï¼ˆè½¬æ¢ä¸ºè¿ç»­æ•´æ•°ï¼‰\n",
    "user_encoder = LabelEncoder()\n",
    "song_encoder = LabelEncoder()\n",
    "\n",
    "# å¯¹ç”¨æˆ·IDå’Œæ­Œæ›²IDè¿›è¡Œç¼–ç \n",
    "merged_data['user_id_encoded'] = user_encoder.fit_transform(merged_data['user_id'])\n",
    "merged_data['song_id_encoded'] = song_encoder.fit_transform(merged_data['song_id'])\n",
    "\n",
    "# 2. å½’ä¸€åŒ–æ’­æ”¾æ¬¡æ•°åˆ° [0,1]\n",
    "max_play = merged_data['plays'].max()\n",
    "merged_data['plays_normalized'] = merged_data['plays'] / max_play\n",
    "\n",
    "# 3. æå–è®­ç»ƒæ•°æ®\n",
    "user_ids = merged_data['user_id_encoded'].values\n",
    "item_ids = merged_data['song_id_encoded'].values\n",
    "labels = merged_data['plays_normalized'].values  # å½’ä¸€åŒ–åçš„æ’­æ”¾æ¬¡æ•°\n",
    "\n",
    "# 4. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "train_user, test_user, train_item, test_item, train_label, test_label = train_test_split(\n",
    "    user_ids, item_ids, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# æ¨¡å‹æ„å»º\n",
    "# ----------------------\n",
    "\n",
    "# å®šä¹‰ç”¨æˆ·å’Œç‰©å“æ•°é‡\n",
    "num_users = len(user_encoder.classes_)  # 105,283\n",
    "num_items = len(song_encoder.classes_)  # 384,546\n",
    "embedding_size = 32  # åµŒå…¥ç»´åº¦\n",
    "\n",
    "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# æ„å»ºGMFæ¨¡å‹ï¼ˆå›å½’ä»»åŠ¡ï¼‰\n",
    "def build_gmf_model():\n",
    "    pretrained_path = \"best_gmf_model.keras\"\n",
    "    \n",
    "    if Path(pretrained_path).exists():\n",
    "        print(\"â³ æ£€æµ‹åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼ŒåŠ è½½ä¸­...\")\n",
    "        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹\n",
    "        model = tf.keras.models.load_model(pretrained_path)\n",
    "        print(\"âœ… æˆåŠŸåŠ è½½é¢„è®­ç»ƒæ¨¡å‹\")\n",
    "        \n",
    "        # å¯é€‰ï¼šè°ƒæ•´å­¦ä¹ ç‡ï¼ˆç»§ç»­è®­ç»ƒæ—¶é€šå¸¸éœ€è¦é™ä½å­¦ä¹ ç‡ï¼‰\n",
    "        new_learning_rate = 0.0001  # åŸå§‹ä¸º0.001\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=new_learning_rate),\n",
    "            loss='mse',\n",
    "            metrics=['mae']\n",
    "        )\n",
    "        print(f\"ğŸ”„ å·²è°ƒæ•´å­¦ä¹ ç‡è‡³ {new_learning_rate}\")\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        print(\"ğŸ†• æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹ï¼Œåˆ›å»ºæ–°æ¨¡å‹\")\n",
    "        user_input = Input(shape=(1,), dtype=tf.int32, name='user_input')\n",
    "        item_input = Input(shape=(1,), dtype=tf.int32, name='item_input')\n",
    "        \n",
    "        # é™ä½åµŒå…¥ç»´åº¦è‡³ 16\n",
    "        user_embed = Embedding(num_users, 16, input_length=1, name='user_embed')(user_input)\n",
    "        item_embed = Embedding(num_items, 16, input_length=1, name='item_embed')(item_input)\n",
    "        \n",
    "        # å±•å¹³ç»´åº¦ (None, 1, 16) -> (None, 16)\n",
    "        user_flatten = tf.keras.layers.Reshape((16,))(user_embed)\n",
    "        item_flatten = tf.keras.layers.Reshape((16,))(item_embed)\n",
    "        \n",
    "        # ç®€åŒ–è®¡ç®—ï¼šç›´æ¥ç‚¹ç§¯ä»£æ›¿ä¹˜æ³•+å…¨è¿æ¥\n",
    "        dot_product = tf.keras.layers.Dot(axes=1)([user_flatten, item_flatten])\n",
    "        \n",
    "        model = Model(inputs=[user_input, item_input], outputs=dot_product)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                    loss='mse', metrics=['mae'])\n",
    "        return model\n",
    "\n",
    "model = build_gmf_model()\n",
    "model.summary()\n",
    "\n",
    "# ----------------------\n",
    "# æ¨¡å‹è®­ç»ƒ\n",
    "# ----------------------\n",
    "\n",
    "# è½¬æ¢ä¸ºTensorFlow Datasetï¼ˆæå‡æ€§èƒ½ï¼‰\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"user_input\": train_user, \"item_input\": train_item}, train_label)\n",
    ").shuffle(100000, reshuffle_each_iteration=True).batch(16384).cache().prefetch(tf.data.AUTOTUNE)  # è‡ªåŠ¨é¢„åŠ è½½\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\"user_input\": test_user, \"item_input\": test_item}, test_label)\n",
    ").batch(16384).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# æ·»åŠ æ¨¡å‹ä¿å­˜å›è°ƒï¼ˆè‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰\n",
    "class CustomCheckpoint(ModelCheckpoint):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # æ·»åŠ ä¼˜åŒ–å™¨çŠ¶æ€ä¿å­˜è·¯å¾„\n",
    "        self.optimizer_path = \"optimizer_state_gmf.pkl\"\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        # ä¿å­˜ä¼˜åŒ–å™¨æƒé‡\n",
    "        joblib.dump(self.model.optimizer.get_weights(), self.optimizer_path)\n",
    "        print(f\"ğŸ’¾ å·²ä¿å­˜ä¼˜åŒ–å™¨çŠ¶æ€è‡³ {self.optimizer_path}\")\n",
    "\n",
    "# é…ç½®æ£€æŸ¥ç‚¹ï¼ˆå¢å¼ºç‰ˆï¼‰\n",
    "checkpoint = CustomCheckpoint(\n",
    "    \"best_gmf_model.keras\",\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# å¦‚æœæ£€æµ‹åˆ°ä¼˜åŒ–å™¨çŠ¶æ€åˆ™åŠ è½½\n",
    "if Path(\"optimizer_state_gmf.pkl\").exists():\n",
    "    print(\"â³ åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€...\")\n",
    "    optimizer_weights = joblib.load(\"optimizer_state_gmf.pkl\")\n",
    "    model.optimizer.set_weights(optimizer_weights)\n",
    "    print(\"âœ… ä¼˜åŒ–å™¨çŠ¶æ€å·²æ¢å¤\")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹ï¼ˆepochså¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=test_dataset,\n",
    "    epochs=100,  # è®¾ç½®è¾ƒå¤§å€¼ï¼Œä¾é æ—©åœæœºåˆ¶\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# æ¨¡å‹è¯„ä¼°ä¸é¢„æµ‹\n",
    "# ----------------------\n",
    "\n",
    "# è¯„ä¼°æµ‹è¯•é›†\n",
    "test_loss, test_mae = model.evaluate(test_dataset)\n",
    "print(f\"testsets MSE: {test_loss:.4f}, MAE: {test_mae:.4f}\")\n",
    "\n",
    "# ä¿å­˜ç¼–ç å™¨ï¼ˆè®­ç»ƒåç«‹å³æ‰§è¡Œï¼‰\n",
    "joblib.dump(max_play, 'max_play_gmf.pkl')\n",
    "joblib.dump(user_encoder, 'user_encoder_gmf.pkl')\n",
    "joblib.dump(song_encoder, 'song_encoder_gmf.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73e8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06b4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'merry christmas mr'\n",
      "1.1 Merry Christmas Mr. Lawrence - Richard Clayderman\n",
      "1.2 Merry Christmas Mr Lawrence - Fact\n",
      "1.3 Merry Christmas Mr Lawrence (Heart Of Asia) (DJ Quicksilver's Radio Edit) - Watergate\n",
      "1.4 Merry Christmas Mr. Lawrence - L'Orchestra Cinematique\n",
      "\n",
      "ğŸ” Results for: 'gymno'\n",
      "2.1 N2 3 Gymnopedies 1888 - Ciccolini_ Aldo / Tacchino_ Gabriel\n",
      "2.2 Gymnopedie #2 - Carl Doy\n",
      "2.3 GymnopÃ©die No. 1 (Demo) - Gary Numan\n",
      "2.4 Gymnopedie #3 - Carl Doy\n",
      "2.5 GymnopÃ©dies for Piano/GymnopÃ©die No. 3 - Alex de Grassi;Paul McCandless\n",
      "==================================================\n",
      "\n",
      "\n",
      "â­ Analyzing song features...\n",
      "ğŸ”¢ Calculating similarities...\n",
      "\n",
      "ğŸ§ Recommended songs for you:\n",
      "                                               title                                 artist_name  predicted_plays\n",
      "Lovin' You So (Dr. Dolittle Soundtrack) (LP Version)                                 Jody Watley        84.708435\n",
      "                                               Alive                                  Solarscape        67.416977\n",
      "                     Break In-City (Storm the Gate!)                                 Tenacious D        64.160583\n",
      "                                         Kill Switch                               Counterstrike        62.223274\n",
      "                                   When I'm With You                               Helen Shapiro        62.133659\n",
      "                                                   B                          SubArachnoid Space        62.089001\n",
      "                                          Nem hinnÃ©m                          Daisy (Papp Daisy)        61.857193\n",
      "                                         Tea for Two                           Marshmallow Coast        60.935658\n",
      "                                       Czar Of Steel                             Derek Sherinian        59.564083\n",
      "                                              Posted The Most Powerful Telescope In the Universe        59.522236\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'A Quiet Thought'\n",
      "\n",
      "ğŸ” Results for: 'merry christmas'\n",
      "2.1 Merry Christmas_ Baby - Charles Brown\n",
      "2.2 Medley: Let It Snow / Frosty The Snowman / Santa Claus Is Comin\u0019 To Town / We Wish You A Merry Christmas - Lee Greenwood\n",
      "2.3 Merry Christmas My Love - Gilli Moon\n",
      "2.4 We Wish You A Merry Christmas - Dora The Explorer\n",
      "2.5 We Wish You A Merry Christmas - Willie Nelson\n",
      "\n",
      "ğŸ” Results for: 'gymno'\n",
      "3.1 N2 3 Gymnopedies 1888 - Ciccolini_ Aldo / Tacchino_ Gabriel\n",
      "3.2 Gymnopedie #2 - Carl Doy\n",
      "3.3 GymnopÃ©die No. 1 (Demo) - Gary Numan\n",
      "3.4 Gymnopedie #3 - Carl Doy\n",
      "3.5 GymnopÃ©dies for Piano/GymnopÃ©die No. 3 - Alex de Grassi;Paul McCandless\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'merry christmas mr'\n",
      "1.1 Merry Christmas Mr. Lawrence - Richard Clayderman\n",
      "1.2 Merry Christmas Mr Lawrence - Fact\n",
      "1.3 Merry Christmas Mr Lawrence (Heart Of Asia) (DJ Quicksilver's Radio Edit) - Watergate\n",
      "1.4 Merry Christmas Mr. Lawrence - L'Orchestra Cinematique\n",
      "\n",
      "ğŸ” Results for: 'gymno'\n",
      "2.1 N2 3 Gymnopedies 1888 - Ciccolini_ Aldo / Tacchino_ Gabriel\n",
      "2.2 Gymnopedie #2 - Carl Doy\n",
      "2.3 GymnopÃ©die No. 1 (Demo) - Gary Numan\n",
      "2.4 Gymnopedie #3 - Carl Doy\n",
      "2.5 GymnopÃ©dies for Piano/GymnopÃ©die No. 3 - Alex de Grassi;Paul McCandless\n",
      "\n",
      "âš ï¸ No results found for: 'A quiet thought'\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'kanon'\n",
      "1.1 Kanona - Foster\n",
      "1.2 Der Weihnachtskanon - Roger Whittaker\n",
      "1.3 Kanonensong - Slut\n",
      "1.4 Arschkanone - Turbostaat\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'kanon'\n",
      "1.1 Kanona - Foster\n",
      "1.2 Der Weihnachtskanon - Roger Whittaker\n",
      "1.3 Kanonensong - Slut\n",
      "1.4 Arschkanone - Turbostaat\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'MARIAGE D'AMOUR'\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "â­ Analyzing song features...\n",
      "âŒ Feature analysis failed: No valid song IDs found\n",
      "Unable to generate recommendations, please try different input\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Castle in the Sky'\n",
      "1.1 Castle In The Sky Feat. Jens Lekman - Montt Mardie\n",
      "1.2 Castle In the Sky - Dj Satomi\n",
      "1.3 Castle In The Sky - The Bop Chords\n",
      "1.4 Castle In The Sky ( Dj Marton Remix ) - Dj Satomi\n",
      "1.5 Castle In The Sky - Simon Dupree & The Big Sound\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "â­ Analyzing song features...\n",
      "âŒ Feature analysis failed: No valid song IDs found\n",
      "Unable to generate recommendations, please try different input\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: '0'\n",
      "1.1 006 - Lena Philipsson\n",
      "1.2 CitÃ©s dortoires (feat. 59 Grammes) - Alpha 5.20\n",
      "1.3 Dalny svet (bonus 2003) - Kruiz\n",
      "1.4 Sonata No. 10 Op. 70 - Mikhail Pletnev\n",
      "1.5 What Can I Do? - Link 80\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Moonlight Sonata'\n",
      "1.1 Moonlight Sonata (L. Beethoven) - Tom Barabas\n",
      "1.2 Moonlight Sonata - Tom Barabas\n",
      "1.3 Moonlight Sonata Reaktor (Music By BEETHOVEN) - Federico Baltimore\n",
      "1.4 Fur Elise/Moonlight Sonata - Vanilla Fudge\n",
      "1.5 Moonlight Sonata (Classic Version) - Myleene Klass\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'River Flows In You'\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Canon in D'\n",
      "1.1 Say You_ Say Canon/Some Say Canon in D - J. Pachelbel\n",
      "1.2 As the Canon in D - J. Pachelbel\n",
      "1.3 Fullness Of Wind (Variation On 'The Canon In D Major' By Johann Pachelbel) (2004 Digital Remaster) - Brian Eno\n",
      "1.4 Pachobel Canon In D - Rick Wakeman\n",
      "1.5 Brutal Ardour (Variation On 'The Canon In D Major' By Johann Pachelbel) (2004 Digital Remaster) - Brian Eno\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'canon'\n",
      "1.1 Snow Canon - Steve Roach\n",
      "1.2 Canon A 2 (Bach) - Arion\n",
      "1.3 Studien fÃ¼r den Pedal-FlÃ¼gel_ 6 Pieces in Canon_ Op. 56 (arr. Theodor Kirchner): III. Andantino - Altenberg Trio Wien\n",
      "1.4 Canon Perpetuus: Super Thema Regium (Bach) - Arion\n",
      "1.5 Canon - Kroke\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'for elise'\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Kiss The Rain'\n",
      "1.1 Kiss The Rain - Dare\n",
      "1.2 Kiss The Rain - Billie Myers\n",
      "1.3 Kiss The Rainbow - Stellar\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Summer'\n",
      "1.1 Summer Of My Life - Archie Roach\n",
      "1.2 The Things We Did Last Summer - The Oscar Peterson Trio\n",
      "1.3 Celebrate the Summer 2006 - Lacuna\n",
      "1.4 Summer Breezin' - George Duke\n",
      "1.5 Summer With You - The 20 Belows\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'Night Piano No.5'\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'Canon Variations'\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'Annie's Wonderland'\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'The Blue Danube'\n",
      "1.1 The Blue Danube - Pierre Vangelis\n",
      "1.2 House Of The Blue Danube - Malcolm McLaren;The Bootzilla Orchestra\n",
      "1.3 Concert Arabesques On The Blue Danube - Earl Wild\n",
      "1.4 Cruisin' in the Blue Danubeoo - Benny Martin\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Minute Waltz'\n",
      "1.1 Black Minute Waltz (Album Version) - James Booker\n",
      "1.2 The Minute Waltz - Helen Hobson\n",
      "1.3 Borge Favourites Medley: Minute Waltz / Liebestraum - Victor Borge\n",
      "1.4 Minute Waltz Boogie - Joe 'Fingers' Carr\n",
      "1.5 Waltz in D-Flat_ Op. 64_ No. 1 (Minute Waltz) - James Galway;Charles Gerhardt\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Symphony No.5'\n",
      "1.1 Symphony No.52 - Movements - Original - Joe Loco\n",
      "1.2 Tchaikovsky's Symphony No 5 In E Minor Op 64: Valse - Allegro Moderato - Leopold Stokowski\n",
      "1.3 Symphony No.5 in C minor Op.67 : II Andante con moto - Daniel Barenboim\n",
      "1.4 Tchaikovsky's Symphony No 5 In E Minor Op 64: Andante Allegro Con Anima - Leopold Stokowski\n",
      "1.5 Honegger : Symphony No.5 in D major_ 'Di tre re' : III Allegro marcato - Charles Dutoit\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Romeo and Juliet'\n",
      "1.1 Romeo And Juliet Ballet Op 64 Suite 2 - Philadelphia Orchestra\n",
      "1.2 Romeo And Juliet - The Killers\n",
      "1.3 Romeo and Juliet Op. 64_ Act III: At Friar Laurence's - London Symphony Orchestra/AndrÃ© Previn\n",
      "1.4 Romeo and Juliet Op. 64 - selections: No. 10_ Juliet the little girl - Royal Liverpool Philharmonic Orchestra/Libor Pesek\n",
      "1.5 Prokofiev: Romeo And Juliet (Selections) - Juliet's Death - Leopold Stokowski\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Serenade'\n",
      "1.1 Serenade No. 13 in G_ 'Eine kleine Nachtmusik' K525 (1997 Digital Remaster): III.  Menuetto (Allegretto) - Sir Neville Marriner/Academy of St Martin-in-the-Fields\n",
      "1.2 Silver's Serenade - The Bronx Horns\n",
      "1.3 Slag Heap Serenade - The Caroloregians\n",
      "1.4 Ferryboat Serenade - Andrews Sisters\n",
      "1.5 Unsere Serenade - Throneberry\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Lullaby'\n",
      "1.1 The Utilitarian Christmas Jingle - Lullaby For The Working Class\n",
      "1.2 Menuet - L'Orchestre Lullabye\n",
      "1.3 Lullaby - Liam Finn\n",
      "1.4 Bamboo Lullaby - Martin Denny\n",
      "1.5 Suicide Note Lullaby - Psyclon Nine\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No results found for: 'Nocturne in E-flat Major'\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Nocturne'\n",
      "1.1 Nocturne For Piano No. 9 In B Minor_ Op. 97 - David Jalbert\n",
      "1.2 Nocturne - Sven-Bertil Taube\n",
      "1.3 Nocturne in C-sharp minor (1830) - Janusz Olejniczak\n",
      "1.4 Nocturne Thule - Eternal Tears Of Sorrow\n",
      "1.5 Confessions Nocturnes (Avec Vitaa) - Diam's\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Swan Lake'\n",
      "1.1 Heartswarm - Swan Lake\n",
      "1.2 Tea (Chinese Dance) - Swan Lake & The Nutcracker\n",
      "1.3 Spider - Swan Lake\n",
      "1.4 No.14. Pas de deux ( prince and sugar-plum fairy) - Swan Lake & The Nutcracker\n",
      "1.5 Swan Lake - Ballet Suite Op.20 (1991 Digital Remaster): Scene (Swan Theme) - Philharmonia Orchestra/Herbert von Karajan\n",
      "==================================================\n",
      "\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "ğŸ” Results for: 'Moonlight Sonata'\n",
      "1.1 Moonlight Sonata (L. Beethoven) - Tom Barabas\n",
      "1.2 Moonlight Sonata - Tom Barabas\n",
      "1.3 Moonlight Sonata Reaktor (Music By BEETHOVEN) - Federico Baltimore\n",
      "1.4 Fur Elise/Moonlight Sonata - Vanilla Fudge\n",
      "1.5 Moonlight Sonata (Classic Version) - Myleene Klass\n",
      "\n",
      "ğŸ” Results for: 'Romeo And Juliet Ballet'\n",
      "2.1 Romeo And Juliet Ballet Op 64 Suite 2 - Philadelphia Orchestra\n",
      "\n",
      "ğŸ” Results for: 'Serenade No. 13'\n",
      "3.1 Serenade No. 13 in G_ 'Eine kleine Nachtmusik' K525 (1997 Digital Remaster): III.  Menuetto (Allegretto) - Sir Neville Marriner/Academy of St Martin-in-the-Fields\n",
      "3.2 Serenade No. 13 in G_ 'Eine kleine Nachtmusik' K525 (1997 Digital Remaster): IV. Rondo (Allegro) - Sir Neville Marriner/Academy of St Martin-in-the-Fields\n",
      "3.3 Serenade No. 13 in G 'Eine kleine Nachtmusik' K525: III.  Menuetto (Allegretto) & Trio - London Mozart Players/Jane Glover\n",
      "3.4 Serenade No. 13 in G 'Eine kleine Nachtmusik' K525: I.   Allegro - London Mozart Players/Jane Glover\n",
      "3.5 Serenade No. 13 in G_ 'Eine kleine Nachtmusik' K525 (1997 Digital Remaster): I.   Allegro - Sir Neville Marriner/Academy of St Martin-in-the-Fields\n",
      "\n",
      "ğŸ” Results for: 'Nocturne For Piano'\n",
      "4.1 Nocturne For Piano No. 9 In B Minor_ Op. 97 - David Jalbert\n",
      "4.2 Nocturne For Piano No. 7 In C Sharp Minor_ Op. 74 - David Jalbert\n",
      "4.3 Nocturne For Piano No. 10 In B Minor_ Op. 99 - David Jalbert\n",
      "4.4 Nocturne For Piano No. 5 In B Flat Major_ Op. 37 - David Jalbert\n",
      "4.5 Nocturne For Piano No. 8 In D Flat Major_ Op. 84 No. 8 (also in Huit piÃ¨ces brÃ¨ves_ Op. 84/8) - David Jalbert\n",
      "\n",
      "ğŸ” Results for: 'Swan Lake - Ballet Suite'\n",
      "5.1 Swan Lake - Ballet Suite Op.20 (1991 Digital Remaster): Scene (Swan Theme) - Philharmonia Orchestra/Herbert von Karajan\n",
      "\n",
      "ğŸ” Results for: 'gymno'\n",
      "6.1 N2 3 Gymnopedies 1888 - Ciccolini_ Aldo / Tacchino_ Gabriel\n",
      "6.2 Gymnopedie #2 - Carl Doy\n",
      "6.3 GymnopÃ©die No. 1 (Demo) - Gary Numan\n",
      "6.4 Gymnopedie #3 - Carl Doy\n",
      "6.5 GymnopÃ©dies for Piano/GymnopÃ©die No. 3 - Alex de Grassi;Paul McCandless\n",
      "==================================================\n",
      "\n",
      "\n",
      "â­ Analyzing song features...\n",
      "ğŸ”¢ Calculating similarities...\n",
      "\n",
      "ğŸ§ Recommended songs for you:\n",
      "                                                       title        artist_name  predicted_plays\n",
      "                                               Up In The Air          Husker Du       138.986160\n",
      "                                         Tango mayor y menor          Paco PeÃ±a        78.968979\n",
      "                                        The Girl That I Love     Russell Morris        64.125572\n",
      "                                                    AbdallÃ¢h               Tryo        56.568665\n",
      "                              Can't Test My Crew feat. Wiley         Dot Rotten        54.491856\n",
      "                                                    The Bell Sons And Daughters        52.830547\n",
      "                                           Ca Plane Pour Moi     Nouvelle Vague        52.648438\n",
      "Promises One By One (Lovin' God & Lovin' Each Other Version) Gaither Vocal Band        50.966419\n",
      "                           Four Minutes In Durham (With You)          Fischer-Z        50.013451\n",
      "                                                       Words    Jack the Ripper        49.478619\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n",
      "\n",
      "==================================================\n",
      "\n",
      "==================================================\n",
      "\n",
      "âš ï¸ No valid selections, try again\n",
      "\n",
      "ğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import h5py\n",
    "# ----------------------\n",
    "# Load metadata \n",
    "# ----------------------\n",
    "def load_metadata(filename):\n",
    "    \"\"\"Metadata loading function identical to the training code\"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        songs_dataset = f['metadata/songs']  # Note the hierarchy uses '/' separators\n",
    "        \n",
    "        # Extract all required fields\n",
    "        song_ids_bytes = songs_dataset['song_id'][()]\n",
    "        titles_bytes = songs_dataset['title'][()]\n",
    "        artists_bytes = songs_dataset['artist_name'][()]  # Added artist field\n",
    "        \n",
    "        # Unified decoding process\n",
    "        decode_func = lambda x: x.decode('utf-8', errors='ignore').strip()\n",
    "        song_ids = list(map(decode_func, song_ids_bytes))\n",
    "        titles = list(map(decode_func, titles_bytes))\n",
    "        artists = list(map(decode_func, artists_bytes))\n",
    "        \n",
    "        # Build DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'song_id': song_ids,\n",
    "            'title': titles,\n",
    "            'artist_name': artists  # Add other required fields\n",
    "        })\n",
    "        \n",
    "        # Filter invalid data\n",
    "        return df[df['song_id'].str.len() > 0]\n",
    "\n",
    "# ----------------------\n",
    "# Enhanced Recommendation System Class\n",
    "# ----------------------\n",
    "class AdvancedMusicRecommender:\n",
    "    def __init__(self):\n",
    "        # Load metadata\n",
    "        self.metadata = load_metadata('msd_summary_file.h5')\n",
    "        \n",
    "        # Load model and encoders\n",
    "        self.model = tf.keras.models.load_model('best_gmf_model.keras')\n",
    "        self.song_encoder = joblib.load('song_encoder_gmf.pkl')\n",
    "        \n",
    "        # Handle missing max_play\n",
    "        try:\n",
    "            self.max_play = joblib.load('max_play_gmf.pkl')\n",
    "        except FileNotFoundError:\n",
    "            print(\"Warning: Estimating max_play using metadata\")\n",
    "            self.max_play = self.metadata['plays'].max() if 'plays' in self.metadata else 1\n",
    "        \n",
    "        # Create song ID to index mapping\n",
    "        self.song_id_to_idx = {\n",
    "            song_id: idx \n",
    "            for idx, song_id in enumerate(self.song_encoder.classes_)\n",
    "        }\n",
    "        \n",
    "        # Get song embeddings\n",
    "        self.song_embeddings = self.model.get_layer('item_embed').get_weights()[0]\n",
    "\n",
    "    def search_songs(self, query, top_k=5):\n",
    "        \"\"\"Modified search function with consistent fields\"\"\"\n",
    "        mask = (\n",
    "            self.metadata['title'].str.contains(query, case=False) |\n",
    "            self.metadata['artist_name'].str.contains(query, case=False)\n",
    "        )\n",
    "        return self.metadata[mask].head(top_k)[['song_id', 'title', 'artist_name']]\n",
    "    \n",
    "    def create_virtual_user(self, song_ids):\n",
    "        \"\"\"Create virtual user features from song IDs\"\"\"\n",
    "        valid_ids = [song_id for song_id in song_ids if song_id in self.song_id_to_idx]\n",
    "        \n",
    "        if not valid_ids:\n",
    "            raise ValueError(\"No valid song IDs found\")\n",
    "            \n",
    "        indices = [self.song_id_to_idx[song_id] for song_id in valid_ids]\n",
    "        avg_embedding = np.mean(self.song_embeddings[indices], axis=0)\n",
    "        return avg_embedding\n",
    "\n",
    "    def _select_songs_interactively(self, matched_songs):\n",
    "        \"\"\"Interactive song selection with re-search option\"\"\"\n",
    "        print(\"\\nğŸ” Found matching songs:\")\n",
    "        print(\"0. Search again (unsatisfied with results)\")\n",
    "        for idx, (_, row) in enumerate(matched_songs.iterrows(), 1):\n",
    "            print(f\"{idx}. {row['title']} - {row['artist_name']}\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                selected = input(\"Enter song numbers (space-separated, 0 to re-search, enter for all): \").strip()\n",
    "                if not selected:\n",
    "                    return matched_songs['song_id'].tolist()\n",
    "                \n",
    "                if '0' in selected.split():\n",
    "                    return None\n",
    "                \n",
    "                indices = list(map(int, selected.split()))\n",
    "                valid_indices = [i for i in indices if 1 <= i <= len(matched_songs)]\n",
    "                \n",
    "                if not valid_indices:\n",
    "                    print(\"âš ï¸ Invalid input, please try again\")\n",
    "                    continue\n",
    "                \n",
    "                return matched_songs.iloc[[i-1 for i in valid_indices]]['song_id'].tolist()\n",
    "            \n",
    "            except ValueError:\n",
    "                print(\"âš ï¸ Please enter valid numbers\")\n",
    "\n",
    "    def _format_grouped_results(self, grouped_results):\n",
    "        \"\"\"Format grouped search results with hierarchical numbering\"\"\"\n",
    "        formatted = []\n",
    "        for group_idx, (query, results) in enumerate(grouped_results, 1):\n",
    "            if not results.empty:\n",
    "                formatted.append(f\"\\nğŸ” Results for: '{query}'\")\n",
    "                for item_idx, (_, row) in enumerate(results.iterrows(), 1):\n",
    "                    formatted.append(f\"{group_idx}.{item_idx} {row['title']} - {row['artist_name']}\")\n",
    "            else:\n",
    "                formatted.append(f\"\\nâš ï¸ No results found for: '{query}'\")\n",
    "        return \"\\n\".join(formatted)\n",
    "\n",
    "    def _parse_group_selection(self, selection, grouped_results):\n",
    "        \"\"\"Parse hierarchical selection like '1.1 2.3'\"\"\"\n",
    "        selected_ids = []\n",
    "        valid_groups = [g for g in grouped_results if not g[1].empty]\n",
    "        \n",
    "        for part in selection.split():\n",
    "            try:\n",
    "                group_num, item_num = map(int, part.split('.'))\n",
    "                # Adjust for valid groups only\n",
    "                if 1 <= group_num <= len(valid_groups):\n",
    "                    group_query, group_df = valid_groups[group_num-1]\n",
    "                    if 1 <= item_num <= len(group_df):\n",
    "                        selected_ids.append(group_df.iloc[item_num-1]['song_id'])\n",
    "            except:\n",
    "                continue\n",
    "        return selected_ids\n",
    "    \n",
    "    def generate_recommendations(self, input_titles, top_n=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Core recommendation generation function (Fixed Version)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Step 1: Process each query separately\n",
    "            grouped_results = []\n",
    "            valid_queries = 0\n",
    "\n",
    "            for query in input_titles:\n",
    "                query = query.strip()\n",
    "                if not query:\n",
    "                    continue\n",
    "\n",
    "                results = self.search_songs(query)\n",
    "                grouped_results.append((query, results))\n",
    "                if not results.empty:\n",
    "                    valid_queries += 1\n",
    "\n",
    "            # Step 2: Display grouped results\n",
    "            if verbose:\n",
    "                print(\"\\n\" + \"=\"*50)\n",
    "                print(self._format_grouped_results(grouped_results))\n",
    "                print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "            # Step 3: Interactive selection\n",
    "            selected_ids = []\n",
    "            while True:\n",
    "                try:\n",
    "                    selection = input(\n",
    "                        \"Enter selections (e.g. '1.1 2.3'), '0' to re-search, or enter to confirm: \"\n",
    "                    ).strip()\n",
    "                    \n",
    "                    if selection == '0':\n",
    "                        return None\n",
    "                    if not selection:\n",
    "                        break\n",
    "                        \n",
    "                    selected_ids = self._parse_group_selection(selection, grouped_results)\n",
    "                    if not selected_ids:\n",
    "                        print(\"âš ï¸ No valid selections, try again\")\n",
    "                        continue\n",
    "                    break\n",
    "                        \n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"\\nâ¹ Selection canceled\")\n",
    "                    if input(\"Continue? (y/n): \").lower() == 'n':\n",
    "                        return pd.DataFrame()\n",
    "\n",
    "            # Step 4: Create virtual user\n",
    "            try:\n",
    "                if verbose:\n",
    "                    print(\"\\nâ­ Analyzing song features...\")\n",
    "                \n",
    "                virtual_user = self.create_virtual_user(selected_ids)\n",
    "            except ValueError as e:\n",
    "                if verbose:\n",
    "                    print(f\"âŒ Feature analysis failed: {str(e)}\")\n",
    "                return pd.DataFrame()\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"âŒ Unexpected error: {str(e)}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Step 5: Calculate similarity (Fixed)\n",
    "            try:\n",
    "                if verbose:\n",
    "                    print(\"ğŸ”¢ Calculating similarities...\")\n",
    "                \n",
    "                scores = np.dot(self.song_embeddings, virtual_user)\n",
    "                \n",
    "                # ä½¿ç”¨å½“å‰é€‰æ‹©çš„IDæ¥æ’é™¤å·²é€‰æ­Œæ›²\n",
    "                input_indices = [\n",
    "                    self.song_id_to_idx[sid] \n",
    "                    for sid in selected_ids  # ä½¿ç”¨å®é™…é€‰æ‹©çš„IDè€Œä¸æ˜¯all_matches\n",
    "                    if sid in self.song_id_to_idx\n",
    "                ]\n",
    "                scores[input_indices] = -np.inf  # æ’é™¤å·²é€‰æ­Œæ›²\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"âŒ Similarity calculation failed: {str(e)}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Step 6: Generate recommendations\n",
    "            try:\n",
    "                top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "                top_scores = scores[top_indices]\n",
    "                top_song_ids = self.song_encoder.inverse_transform(top_indices)\n",
    "\n",
    "                recommendations = self.metadata[\n",
    "                    self.metadata['song_id'].isin(top_song_ids)\n",
    "                ].copy()\n",
    "                \n",
    "                try:\n",
    "                    recommendations['predicted_plays'] = np.clip(\n",
    "                        top_scores * self.max_play, \n",
    "                        0,\n",
    "                        None\n",
    "                    )\n",
    "                except:\n",
    "                    recommendations['predicted_plays'] = 0\n",
    "\n",
    "                return recommendations.sort_values('predicted_plays', ascending=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"âŒ Recommendation generation failed: {str(e)}\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nâ¹ Recommendation process interrupted\")\n",
    "            return pd.DataFrame()\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"â— Unhandled exception: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# ----------------------\n",
    "# Interactive Recommendation Flow\n",
    "# ----------------------\n",
    "def interactive_recommendation():\n",
    "    recommender = AdvancedMusicRecommender()\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\nğŸµ Please enter your favorite songs/artists (enter 'exit' to quit):\")\n",
    "        user_input = input(\"> \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'exit':\n",
    "            break\n",
    "            \n",
    "        queries = [q.strip() for q in user_input.split(',')]\n",
    "        \n",
    "        while True:\n",
    "            result = recommender.generate_recommendations(queries)\n",
    "            if result is None:\n",
    "                break\n",
    "            elif not result.empty:\n",
    "                print(\"\\nğŸ§ Recommended songs for you:\")\n",
    "                print(result[['title', 'artist_name', 'predicted_plays']]\n",
    "                    .head(10).to_string(index=False))\n",
    "                break\n",
    "            else:\n",
    "                print(\"Unable to generate recommendations, please try different input\")\n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_recommendation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
